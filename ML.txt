# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot  as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')


df=pd.read_csv("cancer.csv")

# To print first five rows
df.head()

# count no. of empty(NaN) values in each column
df.isna().sum()

#Drop the column with all missing values
df=df.dropna(axis=1)

# To get  new  no. of columns and rows
df.shape

#Get the count of no. of Malignant(M) or Benign(B) cells
df['diagnosis'].value_counts()




#visualize the count
sns.countplot(df['diagnosis'],label='count')

# Looking at the datatypes to see which columns need to be encoded
df.dtypes

# Encode the categorical data value
from sklearn.preprocessing import LabelEncoder
labelencoder_Y=LabelEncoder()
df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)
df.iloc[:,1]
df.head()

# Create a pairplot
sns.pairplot(df.iloc[:,1:5],hue='diagnosis')
df.head()

# Get the correlation of the columns
df.iloc[:,1:12].corr()

# Visualize the correlation
plt.figure(figsize=(20,20))
sns.heatmap(df.iloc[:,1:12].corr(),annot=True,fmt='0%')

#split the dataset into independent(x) and dependent(y) datasets
x=df.iloc[:,2:31].values
y=df.iloc[:,1].values
type(df)

# Split the data into 75% training and 25% testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train,Y_test=train_test_split(x,y,test_size=0.25,random_state=0)

#Scale the data (feature scaling)
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)
X_train

# Creating a function for the models
def models(X_train,Y_train):
    
    # Logistic Regression
    from sklearn.linear_model import LogisticRegression
    log=LogisticRegression(random_state=0)
    log.fit(X_train,Y_train)
    
    # Decision Tree Classifier
    from sklearn.tree import DecisionTreeClassifier
    tree= DecisionTreeClassifier(criterion='entropy',random_state=0)
    tree.fit(X_train,Y_train)
    
    # RandomForestClassifier
    from sklearn.ensemble import RandomForestClassifier
    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)
    forest.fit(X_train,Y_train)
    
   # SVM
    from sklearn import svm
    support_vector=svm.SVC(kernel='linear',gamma='auto',C=0.3)
    support_vector.fit(X_train,Y_train)

   
    # printing accuracy of models
   
    print('[0] Logistic Regression Training Accuracy:',log.score(X_train,Y_train))
    print('[1] Decision TreeClassifier :',tree.score(X_train,Y_train))

    print('[2] Random Forest Classifier Training Accuracy:',forest.score(X_train,Y_train))
    print('[3] Support Vector Machine Training Accuracy:',support_vector.score(X_train,Y_train))
   
    return log, tree, forest, support_vector

# Getting all of the models
model=models(X_train,Y_train)
model

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
for i in range(len(model)):
    print('Model',i)
    print(classification_report(Y_test,model[i].predict(X_test)))
    print(accuracy_score(Y_test,model[i].predict(X_test)))
